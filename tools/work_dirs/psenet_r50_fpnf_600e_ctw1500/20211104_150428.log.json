{"env_info": "sys.platform: linux\nPython: 3.7.9 (default, Aug 31 2020, 12:42:55) [GCC 7.3.0]\nCUDA available: True\nGPU 0,1: GeForce GTX 1080 Ti\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 10.1, V10.1.168\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.5.1+cu101\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 7.6.3\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n\nTorchVision: 0.6.1+cu101\nOpenCV: 4.4.0\nMMCV: 1.2.4\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 10.1\nMMOCR: 0.1.0+", "config": "model = dict(\n    type='PSENet',\n    pretrained='torchvision://resnet50',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=-1,\n        norm_cfg=dict(type='SyncBN', requires_grad=True),\n        norm_eval=True,\n        style='caffe'),\n    neck=dict(\n        type='FPNF',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        fusion_type='concat'),\n    bbox_head=dict(\n        type='PSEHead',\n        text_repr_type='poly',\n        in_channels=[256],\n        out_channels=7,\n        loss=dict(type='PSELoss')),\n    train_cfg=None,\n    test_cfg=None)\ndataset_type = 'IcdarDataset'\ndata_root = '/media/yons/myspace1/dataset/OcrDataset/CTW1500/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='LoadTextAnnotations',\n        with_bbox=True,\n        with_mask=True,\n        poly2mask=False),\n    dict(type='ColorJitter', brightness=0.12549019607843137, saturation=0.5),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(\n        type='ScaleAspectJitter',\n        img_scale=[(3000, 736)],\n        ratio_range=(0.5, 3),\n        aspect_ratio_range=(1, 1),\n        multiscale_mode='value',\n        long_size_bound=1280,\n        short_size_bound=640,\n        resize_type='long_short_bound',\n        keep_ratio=False),\n    dict(type='PSENetTargets'),\n    dict(type='RandomFlip', flip_ratio=0.5, direction='horizontal'),\n    dict(type='RandomRotateTextDet'),\n    dict(\n        type='RandomCropInstances',\n        target_size=(640, 640),\n        instance_key='gt_kernels'),\n    dict(type='Pad', size_divisor=32),\n    dict(\n        type='CustomFormatBundle',\n        keys=['gt_kernels', 'gt_mask'],\n        visualize=dict(flag=False, boundary_key='gt_kernels')),\n    dict(type='Collect', keys=['img', 'gt_kernels', 'gt_mask'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1280, 1280),\n        flip=False,\n        transforms=[\n            dict(type='Resize', img_scale=(1280, 1280), keep_ratio=True),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type='IcdarDataset',\n        ann_file=\n        '/media/yons/myspace1/dataset/OcrDataset/CTW1500/json_style/instances_training.json',\n        img_prefix='/media/yons/myspace1/dataset/OcrDataset/CTW1500//imgs',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='LoadTextAnnotations',\n                with_bbox=True,\n                with_mask=True,\n                poly2mask=False),\n            dict(\n                type='ColorJitter',\n                brightness=0.12549019607843137,\n                saturation=0.5),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(\n                type='ScaleAspectJitter',\n                img_scale=[(3000, 736)],\n                ratio_range=(0.5, 3),\n                aspect_ratio_range=(1, 1),\n                multiscale_mode='value',\n                long_size_bound=1280,\n                short_size_bound=640,\n                resize_type='long_short_bound',\n                keep_ratio=False),\n            dict(type='PSENetTargets'),\n            dict(type='RandomFlip', flip_ratio=0.5, direction='horizontal'),\n            dict(type='RandomRotateTextDet'),\n            dict(\n                type='RandomCropInstances',\n                target_size=(640, 640),\n                instance_key='gt_kernels'),\n            dict(type='Pad', size_divisor=32),\n            dict(\n                type='CustomFormatBundle',\n                keys=['gt_kernels', 'gt_mask'],\n                visualize=dict(flag=False, boundary_key='gt_kernels')),\n            dict(type='Collect', keys=['img', 'gt_kernels', 'gt_mask'])\n        ]),\n    val=dict(\n        type='IcdarDataset',\n        ann_file=\n        '/media/yons/myspace1/dataset/OcrDataset/CTW1500/json_style/instances_training.json',\n        img_prefix='/media/yons/myspace1/dataset/OcrDataset/CTW1500//imgs',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1280, 1280),\n                flip=False,\n                transforms=[\n                    dict(\n                        type='Resize', img_scale=(1280, 1280),\n                        keep_ratio=True),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    test=dict(\n        type='IcdarDataset',\n        ann_file=\n        '/media/yons/myspace1/dataset/OcrDataset/CTW1500/json_style/instances_training.json',\n        img_prefix='/media/yons/myspace1/dataset/OcrDataset/CTW1500//imgs',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1280, 1280),\n                flip=False,\n                transforms=[\n                    dict(\n                        type='Resize', img_scale=(1280, 1280),\n                        keep_ratio=True),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nevaluation = dict(interval=10, metric='hmean-iou')\noptimizer = dict(type='Adam', lr=0.0001)\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='step', step=[200, 400])\ntotal_epochs = 600\ncheckpoint_config = dict(interval=1)\nlog_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\nwork_dir = './work_dirs/psenet_r50_fpnf_600e_ctw1500'\ngpu_ids = range(0, 1)\n", "seed": null, "exp_name": "psenet_r50_fpnf_600e_ctw1500.py"}
{"mode": "train", "epoch": 1, "iter": 5, "lr": 0.0001, "memory": 3125, "data_time": 0.60682, "loss_text": 0.31532, "loss_kernel": 0.17011, "loss": 0.48543, "time": 0.79455}
{"mode": "train", "epoch": 1, "iter": 10, "lr": 0.0001, "memory": 3125, "data_time": 0.13315, "loss_text": 0.26063, "loss_kernel": 0.14076, "loss": 0.40139, "time": 0.31043}
{"mode": "train", "epoch": 1, "iter": 15, "lr": 0.0001, "memory": 3125, "data_time": 0.32095, "loss_text": 0.29857, "loss_kernel": 0.14567, "loss": 0.44425, "time": 0.50602}
{"mode": "train", "epoch": 1, "iter": 20, "lr": 0.0001, "memory": 3125, "data_time": 0.09894, "loss_text": 0.39069, "loss_kernel": 0.20671, "loss": 0.5974, "time": 0.27919}
{"mode": "train", "epoch": 1, "iter": 25, "lr": 0.0001, "memory": 3125, "data_time": 0.41334, "loss_text": 0.27214, "loss_kernel": 0.13775, "loss": 0.40989, "time": 0.59544}
{"mode": "train", "epoch": 1, "iter": 30, "lr": 0.0001, "memory": 3125, "data_time": 0.14516, "loss_text": 0.32374, "loss_kernel": 0.16863, "loss": 0.49237, "time": 0.32364}
{"mode": "train", "epoch": 1, "iter": 35, "lr": 0.0001, "memory": 3125, "data_time": 0.10843, "loss_text": 0.27905, "loss_kernel": 0.1527, "loss": 0.43175, "time": 0.28743}
{"mode": "train", "epoch": 1, "iter": 40, "lr": 0.0001, "memory": 3125, "data_time": 0.2106, "loss_text": 0.30698, "loss_kernel": 0.17808, "loss": 0.48506, "time": 0.3908}
{"mode": "train", "epoch": 1, "iter": 45, "lr": 0.0001, "memory": 3125, "data_time": 0.09056, "loss_text": 0.31652, "loss_kernel": 0.17094, "loss": 0.48746, "time": 0.27296}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0001, "memory": 3125, "data_time": 0.08481, "loss_text": 0.29301, "loss_kernel": 0.13553, "loss": 0.42854, "time": 0.26549}
{"mode": "train", "epoch": 1, "iter": 55, "lr": 0.0001, "memory": 3125, "data_time": 0.13137, "loss_text": 0.28827, "loss_kernel": 0.14433, "loss": 0.4326, "time": 0.31384}
{"mode": "train", "epoch": 1, "iter": 60, "lr": 0.0001, "memory": 3125, "data_time": 0.19494, "loss_text": 0.35456, "loss_kernel": 0.16678, "loss": 0.52134, "time": 0.37308}
{"mode": "train", "epoch": 1, "iter": 65, "lr": 0.0001, "memory": 3125, "data_time": 0.11026, "loss_text": 0.28643, "loss_kernel": 0.12981, "loss": 0.41623, "time": 0.28984}
{"mode": "train", "epoch": 1, "iter": 70, "lr": 0.0001, "memory": 3125, "data_time": 0.16079, "loss_text": 0.23969, "loss_kernel": 0.12068, "loss": 0.36036, "time": 0.34394}
{"mode": "train", "epoch": 1, "iter": 75, "lr": 0.0001, "memory": 3125, "data_time": 0.13161, "loss_text": 0.23476, "loss_kernel": 0.10851, "loss": 0.34327, "time": 0.31271}
{"mode": "train", "epoch": 1, "iter": 80, "lr": 0.0001, "memory": 3125, "data_time": 0.51828, "loss_text": 0.25491, "loss_kernel": 0.10633, "loss": 0.36124, "time": 0.69505}
{"mode": "train", "epoch": 1, "iter": 85, "lr": 0.0001, "memory": 3125, "data_time": 0.0331, "loss_text": 0.40478, "loss_kernel": 0.20471, "loss": 0.60949, "time": 0.22109}
{"mode": "train", "epoch": 1, "iter": 90, "lr": 0.0001, "memory": 3125, "data_time": 0.13655, "loss_text": 0.33187, "loss_kernel": 0.1604, "loss": 0.49227, "time": 0.31695}
{"mode": "train", "epoch": 1, "iter": 95, "lr": 0.0001, "memory": 3125, "data_time": 0.03335, "loss_text": 0.24869, "loss_kernel": 0.11781, "loss": 0.3665, "time": 0.21219}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.0001, "memory": 3125, "data_time": 0.19727, "loss_text": 0.20212, "loss_kernel": 0.09338, "loss": 0.29549, "time": 0.38039}
{"mode": "train", "epoch": 1, "iter": 105, "lr": 0.0001, "memory": 3125, "data_time": 0.22228, "loss_text": 0.30333, "loss_kernel": 0.14955, "loss": 0.45288, "time": 0.40075}
{"mode": "train", "epoch": 1, "iter": 110, "lr": 0.0001, "memory": 3125, "data_time": 0.19235, "loss_text": 0.27886, "loss_kernel": 0.13359, "loss": 0.41246, "time": 0.37563}
{"mode": "train", "epoch": 1, "iter": 115, "lr": 0.0001, "memory": 3125, "data_time": 0.04005, "loss_text": 0.25037, "loss_kernel": 0.13018, "loss": 0.38055, "time": 0.22065}
{"mode": "train", "epoch": 1, "iter": 120, "lr": 0.0001, "memory": 3125, "data_time": 0.18839, "loss_text": 0.29116, "loss_kernel": 0.13045, "loss": 0.42161, "time": 0.36753}
{"mode": "train", "epoch": 1, "iter": 125, "lr": 0.0001, "memory": 3125, "data_time": 0.12432, "loss_text": 0.32847, "loss_kernel": 0.15077, "loss": 0.47924, "time": 0.30306}
{"mode": "train", "epoch": 1, "iter": 130, "lr": 0.0001, "memory": 3125, "data_time": 0.27791, "loss_text": 0.38227, "loss_kernel": 0.16589, "loss": 0.54816, "time": 0.45953}
{"mode": "train", "epoch": 1, "iter": 135, "lr": 0.0001, "memory": 3125, "data_time": 0.22799, "loss_text": 0.22661, "loss_kernel": 0.09678, "loss": 0.32339, "time": 0.40611}
{"mode": "train", "epoch": 1, "iter": 140, "lr": 0.0001, "memory": 3125, "data_time": 0.15744, "loss_text": 0.22393, "loss_kernel": 0.10811, "loss": 0.33205, "time": 0.33469}
