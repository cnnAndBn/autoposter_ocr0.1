{"env_info": "sys.platform: linux\nPython: 3.7.9 (default, Aug 31 2020, 12:42:55) [GCC 7.3.0]\nCUDA available: True\nGPU 0,1: GeForce GTX 1080 Ti\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 10.1, V10.1.168\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.5.1+cu101\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 7.6.3\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n\nTorchVision: 0.6.1+cu101\nOpenCV: 4.4.0\nMMCV: 1.2.4\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 10.1\nMMOCR: 0.1.0+", "config": "model = dict(\n    type='PSENet',\n    pretrained='torchvision://resnet50',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=-1,\n        norm_cfg=dict(type='SyncBN', requires_grad=True),\n        norm_eval=True,\n        style='caffe'),\n    neck=dict(\n        type='FPNF',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        fusion_type='concat'),\n    bbox_head=dict(\n        type='PSEHead',\n        text_repr_type='poly',\n        in_channels=[256],\n        out_channels=7,\n        loss=dict(type='PSELoss')),\n    train_cfg=None,\n    test_cfg=None)\ndataset_type = 'IcdarDataset'\ndata_root = '/media/yons/myspace1/dataset/OcrDataset/CTW1500/'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='LoadTextAnnotations',\n        with_bbox=True,\n        with_mask=True,\n        poly2mask=False),\n    dict(type='ColorJitter', brightness=0.12549019607843137, saturation=0.5),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(\n        type='ScaleAspectJitter',\n        img_scale=[(3000, 736)],\n        ratio_range=(0.5, 3),\n        aspect_ratio_range=(1, 1),\n        multiscale_mode='value',\n        long_size_bound=1280,\n        short_size_bound=640,\n        resize_type='long_short_bound',\n        keep_ratio=False),\n    dict(type='PSENetTargets'),\n    dict(type='RandomFlip', flip_ratio=0.5, direction='horizontal'),\n    dict(type='RandomRotateTextDet'),\n    dict(\n        type='RandomCropInstances',\n        target_size=(640, 640),\n        instance_key='gt_kernels'),\n    dict(type='Pad', size_divisor=32),\n    dict(\n        type='CustomFormatBundle',\n        keys=['gt_kernels', 'gt_mask'],\n        visualize=dict(flag=False, boundary_key='gt_kernels')),\n    dict(type='Collect', keys=['img', 'gt_kernels', 'gt_mask'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1280, 1280),\n        flip=False,\n        transforms=[\n            dict(type='Resize', img_scale=(1280, 1280), keep_ratio=True),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=1,\n    train=dict(\n        type='IcdarDataset',\n        ann_file=\n        '/media/yons/myspace1/dataset/OcrDataset/CTW1500/json_style/instances_training.json',\n        img_prefix='/media/yons/myspace1/dataset/OcrDataset/CTW1500//imgs',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='LoadTextAnnotations',\n                with_bbox=True,\n                with_mask=True,\n                poly2mask=False),\n            dict(\n                type='ColorJitter',\n                brightness=0.12549019607843137,\n                saturation=0.5),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(\n                type='ScaleAspectJitter',\n                img_scale=[(3000, 736)],\n                ratio_range=(0.5, 3),\n                aspect_ratio_range=(1, 1),\n                multiscale_mode='value',\n                long_size_bound=1280,\n                short_size_bound=640,\n                resize_type='long_short_bound',\n                keep_ratio=False),\n            dict(type='PSENetTargets'),\n            dict(type='RandomFlip', flip_ratio=0.5, direction='horizontal'),\n            dict(type='RandomRotateTextDet'),\n            dict(\n                type='RandomCropInstances',\n                target_size=(640, 640),\n                instance_key='gt_kernels'),\n            dict(type='Pad', size_divisor=32),\n            dict(\n                type='CustomFormatBundle',\n                keys=['gt_kernels', 'gt_mask'],\n                visualize=dict(flag=False, boundary_key='gt_kernels')),\n            dict(type='Collect', keys=['img', 'gt_kernels', 'gt_mask'])\n        ]),\n    val=dict(\n        type='IcdarDataset',\n        ann_file=\n        '/media/yons/myspace1/dataset/OcrDataset/CTW1500/json_style/instances_training.json',\n        img_prefix='/media/yons/myspace1/dataset/OcrDataset/CTW1500//imgs',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1280, 1280),\n                flip=False,\n                transforms=[\n                    dict(\n                        type='Resize', img_scale=(1280, 1280),\n                        keep_ratio=True),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    test=dict(\n        type='IcdarDataset',\n        ann_file=\n        '/media/yons/myspace1/dataset/OcrDataset/CTW1500/json_style/instances_training.json',\n        img_prefix='/media/yons/myspace1/dataset/OcrDataset/CTW1500//imgs',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1280, 1280),\n                flip=False,\n                transforms=[\n                    dict(\n                        type='Resize', img_scale=(1280, 1280),\n                        keep_ratio=True),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nevaluation = dict(interval=10, metric='hmean-iou')\noptimizer = dict(type='Adam', lr=0.0001)\noptimizer_config = dict(grad_clip=None)\nlr_config = dict(policy='step', step=[200, 400])\ntotal_epochs = 600\ncheckpoint_config = dict(interval=1)\nlog_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\nwork_dir = './work_dirs/psenet_r50_fpnf_600e_ctw1500'\ngpu_ids = range(0, 1)\n", "seed": null, "exp_name": "psenet_r50_fpnf_600e_ctw1500.py"}
